{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download required library and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install scipy tensorflow pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the paths for training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'Rock-Paper-Scissors' # Root directory\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'test')\n",
    "test_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "paper_dir = os.path.join(train_dir, 'paper')\n",
    "rock_dir = os.path.join(train_dir, 'rock')\n",
    "scissors_dir = os.path.join(train_dir, 'scissors')\n",
    "\n",
    "paper_imgs = os.listdir(paper_dir)\n",
    "rock_imgs = os.listdir(rock_dir)\n",
    "scissors_imgs = os.listdir(scissors_dir)\n",
    "\n",
    "# Create ImageDataGenerator for data augmentation and preprocessing\n",
    "\n",
    "\n",
    "# Load training dataset\n",
    "\n",
    "\n",
    "# Load test datset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the batch size, learning rate, epochs, target size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "TARGET_SIZE = 64\n",
    "EPOCHS = 10\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Showing some sample datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot images\n",
    "def plot_images_from_dir(image_list, class_name, image_dir, num_images=5):\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i, img_name in enumerate(image_list[:num_images]):\n",
    "        sp = plt.subplot(1, num_images, i+1)\n",
    "        img = mpimg.imread(os.path.join(image_dir, img_name))\n",
    "        plt.imshow(img)\n",
    "        plt.title(class_name)  # Display the class name (e.g., Rock, Paper, Scissors)\n",
    "        plt.axis('off')  # Hide axes\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Displaying sample images for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, MaxPooling2D, Conv2D\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(2,2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "\n",
    "optimizer = optimizers.Adam(0.0001)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
